[
  {
    "model":"gpt-4o-mini-2024-07-18",
    "lower":1246.2255359637,
    "rating":1259.3906491519,
    "upper":1271.8136392157,
    "error_y":12.4229900638,
    "error_y_minus":13.1651131881,
    "rating_rounded":1259.39,
    "name":"gpt-4o-mini"
  },
  {
    "model":"yi-large-preview",
    "lower":1222.397551876,
    "rating":1229.0290729634,
    "upper":1236.4023248749,
    "error_y":7.3732519115,
    "error_y_minus":6.6315210874,
    "rating_rounded":1229.03,
    "name":"yi-large-preview"
  },
  {
    "model":"llama-3-70b-instruct",
    "lower":1206.5509712231,
    "rating":1211.6650457757,
    "upper":1216.3739769008,
    "error_y":4.7089311252,
    "error_y_minus":5.1140745526,
    "rating_rounded":1211.67,
    "name":"Meta-Llama3-70B-Instruct"
  },
  {
    "model":"gpt-4-0314",
    "lower":1175.1209065653,
    "rating":1183.7258129699,
    "upper":1191.8973239801,
    "error_y":8.1715110101,
    "error_y_minus":8.6049064047,
    "rating_rounded":1183.73,
    "name":"gpt-4"
  },
  {
    "model":"yi-1.5-34b-chat",
    "lower":1151.5645827831,
    "rating":1159.2336363586,
    "upper":1167.4450463278,
    "error_y":8.2114099692,
    "error_y_minus":7.6690535754,
    "rating_rounded":1159.23,
    "name":"Yi-1.5-34B-Chat"
  },
  {
    "model":"llama-3-8b-instruct",
    "lower":1137.4934837925,
    "rating":1143.4083931621,
    "upper":1149.5431028534,
    "error_y":6.1347096913,
    "error_y_minus":5.9149093696,
    "rating_rounded":1143.41,
    "name":"Meta-Llama-3-8B-Instruct"
  },
  {
    "model":"claude-1",
    "lower":1108.8668760759,
    "rating":1116.4881463443,
    "upper":1126.5469265446,
    "error_y":10.0587802004,
    "error_y_minus":7.6212702684,
    "rating_rounded":1116.49,
    "name":"claude-v1"
  },
  {
    "model":"claude-instant-1",
    "lower":1087.3138644741,
    "rating":1099.5068402103,
    "upper":1108.5683506126,
    "error_y":9.0615104024,
    "error_y_minus":12.1929757361,
    "rating_rounded":1099.51,
    "name":"claude-instant-v1"
  },
  {
    "model":"vicuna-33b",
    "lower":1051.0119042538,
    "rating":1059.7691730014,
    "upper":1070.2255273405,
    "error_y":10.456354339,
    "error_y_minus":8.7572687476,
    "rating_rounded":1059.77,
    "name":"vicuna-33b-v1.3"
  },
  {
    "model":"vicuna-13b",
    "lower":1005.7047059844,
    "rating":1015.9464430252,
    "upper":1026.0746966026,
    "error_y":10.1282535774,
    "error_y_minus":10.2417370407,
    "rating_rounded":1015.95,
    "name":"vicuna-13b-v1.2"
  }
]